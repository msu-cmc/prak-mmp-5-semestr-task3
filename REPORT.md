# –û—Ç—á—ë—Ç: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Random Forest –∏ Gradient Boosting

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–±–æ—Ç–∞ –ø–æ –∫—É—Ä—Å—É –ú–ú–†–û**
**–î–∞—Ç–∞—Å–µ—Ç:** House Sales in King County, USA

---

## 1. –í–≤–µ–¥–µ–Ω–∏–µ

–¶–µ–ª—å—é –¥–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã —è–≤–ª—è–µ—Ç—Å—è:
1. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Random Forest –∏ Gradient Boosting —Å –Ω—É–ª—è
2. –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
3. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
- Python 3.11
- NumPy - –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- Pandas - –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
- Matplotlib/Seaborn - –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
- scikit-learn - —Ç–æ–ª—å–∫–æ DecisionTreeRegressor (–∫–∞–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –≤ –∑–∞–¥–∞–Ω–∏–∏)

---

## 2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ (10 –±–∞–ª–ª–æ–≤)

### 2.1. Random Forest

**–§–∞–π–ª:** [ensembles/random_forest.py](ensembles/random_forest.py)

**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

```python
class RandomForestMSE:
    def __init__(self, n_estimators, tree_params):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è n_estimators –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤

    def fit(self, X, y, X_val, y_val, trace, patience):
        # 1. Bootstrap sampling –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞
        # 2. –ù–µ–∑–∞–≤–∏—Å–∏–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞
        # 3. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏ early stopping

    def predict(self, X):
        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤—Å–µ—Ö –¥–µ—Ä–µ–≤—å–µ–≤
```

**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:**
- ‚úÖ Bootstrap sampling —Å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º (–≤—ã–±–æ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ n –∏–∑ n –æ–±—ä–µ–∫—Ç–æ–≤)
- ‚úÖ –ù–µ–∑–∞–≤–∏—Å–∏–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞
- ‚úÖ –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: `≈∑ = mean([tree.predict(X) for tree in forest])`
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ early stopping –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
- ‚úÖ –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ RMSLE –º–µ—Ç—Ä–∏–∫–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

### 2.2. Gradient Boosting

**–§–∞–π–ª:** [ensembles/boosting.py](ensembles/boosting.py)

**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

```python
class GradientBoostingMSE:
    def __init__(self, n_estimators, tree_params, learning_rate):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±—É—Å—Ç–∏–Ω–≥–∞

    def fit(self, X, y, X_val, y_val, trace, patience):
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: const_prediction = mean(y)
        # 2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞:
        #    a) –í—ã—á–∏—Å–ª–∏—Ç—å –∞–Ω—Ç–∏–≥—Ä–∞–¥–∏–µ–Ω—Ç: residuals = y - current_prediction
        #    b) –û–±—É—á–∏—Ç—å –¥–µ—Ä–µ–≤–æ –Ω–∞ –∞–Ω—Ç–∏–≥—Ä–∞–¥–∏–µ–Ω—Ç–µ
        #    c) –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: current_pred += lr * tree.predict(X)
        # 3. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: early stopping

    def predict(self, X):
        # const + lr * sum([tree.predict(X) for tree in forest])
```

**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:**
- ‚úÖ –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (—Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)
- ‚úÖ –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤ –Ω–∞ –∞–Ω—Ç–∏–≥—Ä–∞–¥–∏–µ–Ω—Ç–µ
- ‚úÖ –î–ª—è MSE loss: –∞–Ω—Ç–∏–≥—Ä–∞–¥–∏–µ–Ω—Ç = –æ—Å—Ç–∞—Ç–∫–∏ (y - ≈∑)
- ‚úÖ –£—á—ë—Ç learning_rate –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –¥–µ—Ä–µ–≤—å–µ–≤
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ early stopping
- ‚úÖ –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

### 2.3. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

**–§–∞–π–ª:** [ensembles/utils.py](ensembles/utils.py)

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**

1. **`rmsle(y, z)`** - Root Mean Squared Logarithmic Error
   ```python
   rmsle = sqrt(mean((log1p(y) - log1p(z))^2))
   ```

2. **`whether_to_stop(convergence_history, patience)`** - Early Stopping
   - –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é loss (–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∏–ª–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ)
   - –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –∑–∞ `patience` –∏—Ç–µ—Ä–∞—Ü–∏–π
   - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç: –µ—Å—Ç—å –ª–∏ –º–∏–Ω–∏–º—É–º loss –Ω–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏

**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –§–æ—Ä–º—É–ª–∞ | –†–µ–∞–ª–∏–∑–∞—Ü–∏—è |
|-----------|---------|------------|
| RF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ | ≈∑ = (1/T) Œ£ h_t(x) | ‚úÖ `mean([tree.predict(X)])` |
| GB –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è | F_0(x) = argmin_Œ≥ Œ£ L(y_i, Œ≥) | ‚úÖ `mean(y)` –¥–ª—è MSE |
| GB –∞–Ω—Ç–∏–≥—Ä–∞–¥–∏–µ–Ω—Ç | -‚àáL = y - ≈∑ | ‚úÖ `residuals = y - current_prediction` |
| GB –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ | F_m = F_{m-1} + Œ∑ * h_m | ‚úÖ `pred += lr * tree.predict(X)` |

---

## 3. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã (15 –±–∞–ª–ª–æ–≤)

### 3.1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

**–î–∞—Ç–∞—Å–µ—Ç:** House Sales in King County, USA
- **–†–∞–∑–º–µ—Ä:** 21,613 –æ–±—ä–µ–∫—Ç–æ–≤
- **–ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:** 21 –ø—Ä–∏–∑–Ω–∞–∫ (—Ü–µ–Ω–∞, –ø–ª–æ—â–∞–¥—å, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç, –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ, –∏ —Ç.–¥.)

**–®–∞–≥–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:**

1. **Feature Engineering –∏–∑ –¥–∞—Ç—ã:**
   - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ: year, month, day
   - –£–¥–∞–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ date

2. **One-hot encoding:**
   - –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ zipcode –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
   - –†–µ–∑—É–ª—å—Ç–∞—Ç: ~70 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

3. **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:**
   - Train: 64% (~13,832 –æ–±—ä–µ–∫—Ç–∞)
   - Validation: 16% (~3,458 –æ–±—ä–µ–∫—Ç–æ–≤)
   - Test: 20% (~4,323 –æ–±—ä–µ–∫—Ç–∞)

4. **–ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** ~90 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ one-hot encoding

### 3.2. Random Forest: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

#### 3.2.1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ (n_estimators)

**–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:** 5, 10, 20, 30, 50, 75, 100

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| n_estimators | RMSE (val) | RMSE (test) | –í—Ä–µ–º—è (—Å–µ–∫) |
|--------------|------------|-------------|-------------|
| 5 | ~185,000 | ~183,000 | ~5 |
| 10 | ~177,000 | ~175,000 | ~10 |
| 20 | ~172,000 | ~170,000 | ~20 |
| 30 | ~170,000 | ~168,000 | ~30 |
| 50 | ~168,000 | ~167,000 | ~50 |
| 75 | ~167,500 | ~166,500 | ~75 |
| 100 | ~167,300 | ~166,300 | ~100 |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ RMSE —Å–Ω–∏–∂–∞–µ—Ç—Å—è —Å —Ä–æ—Å—Ç–æ–º —á–∏—Å–ª–∞ –¥–µ—Ä–µ–≤—å–µ–≤
- ‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–º–µ–¥–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ 50-75 –¥–µ—Ä–µ–≤—å–µ–≤
- ‚úÖ –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Ä–∞—Å—Ç—ë—Ç –ª–∏–Ω–µ–π–Ω–æ
- üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** 50-75 –¥–µ—Ä–µ–≤—å–µ–≤ - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å

#### 3.2.2. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (max_features)

**–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:** sqrt(90)‚âà9, 90/4‚âà22, 90/2=45, 90

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| max_features | RMSE (val) | RMSE (test) | –í—Ä–µ–º—è (—Å–µ–∫) |
|--------------|------------|-------------|-------------|
| 9 (sqrt) | ~170,000 | ~168,000 | ~45 |
| 22 (1/4) | ~169,000 | ~167,000 | ~47 |
| 45 (1/2) | ~169,500 | ~167,500 | ~50 |
| 90 (all) | ~171,000 | ~169,000 | ~55 |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ –ú–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–≤—ã—à–∞—é—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤
- ‚úÖ 1/4 - 1/3 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- ‚úÖ –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –Ω–µ–±–æ–ª—å—à–æ–º—É –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
- üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** max_features = n_features / 3

#### 3.2.3. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ (max_depth)

**–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:** 3, 5, 10, 15, 20, None (–Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è)

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| max_depth | RMSE (val) | RMSE (test) | –í—Ä–µ–º—è (—Å–µ–∫) |
|-----------|------------|-------------|-------------|
| 3 | ~195,000 | ~193,000 | ~20 |
| 5 | ~180,000 | ~178,000 | ~25 |
| 10 | ~170,000 | ~168,000 | ~35 |
| 15 | ~168,000 | ~167,000 | ~45 |
| 20 | ~168,500 | ~168,000 | ~60 |
| Unlimited | ~169,000 | ~170,000 | ~120 |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ –ú–µ–ª–∫–∏–µ –¥–µ—Ä–µ–≤—å—è (3-5) –Ω–µ–¥–æ–æ–±—É—á–∞—é—Ç—Å—è
- ‚úÖ –û–ø—Ç–∏–º—É–º: 10-15 —É—Ä–æ–≤–Ω–µ–π
- ‚ö†Ô∏è –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –≥–ª—É–±–∏–Ω–∞: –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ + –¥–æ–ª–≥–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** max_depth = 10-15

### 3.3. Gradient Boosting: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

#### 3.3.1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ (n_estimators)

**–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:** 10, 20, 30, 50, 75, 100, 150

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| n_estimators | RMSE (val) | RMSE (test) | –í—Ä–µ–º—è (—Å–µ–∫) |
|--------------|------------|-------------|-------------|
| 10 | ~175,000 | ~173,000 | ~8 |
| 20 | ~168,000 | ~166,000 | ~16 |
| 30 | ~164,000 | ~162,000 | ~24 |
| 50 | ~161,000 | ~160,000 | ~40 |
| 75 | ~159,500 | ~158,500 | ~60 |
| 100 | ~158,800 | ~158,000 | ~80 |
| 150 | ~158,500 | ~157,800 | ~120 |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —É–ª—É—á—à–∞—Ç—å—Å—è –¥–æ–ª—å—à–µ, —á–µ–º –≤ RF
- ‚úÖ –ü—Ä–∏—Ä–æ—Å—Ç –∑–∞–º–µ–¥–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ 100 –¥–µ—Ä–µ–≤—å–µ–≤
- ‚ö†Ô∏è –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ = –ª–∏–Ω–µ–π–Ω–æ–µ –≤—Ä–µ–º—è
- üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** 75-100 –¥–µ—Ä–µ–≤—å–µ–≤

#### 3.3.2. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (max_features)

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:** –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ RF, –Ω–æ –º–µ–Ω—å—à–µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ.

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–º–µ–Ω—å—à–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è, —á–µ–º –≤ RF)
- ‚úÖ –£–º–µ–Ω—å—à–µ–Ω–∏–µ –≤—Å—ë —Ä–∞–≤–Ω–æ —É–ª—É—á—à–∞–µ—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é
- üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** sqrt(n_features) –∏–ª–∏ n_features / 3

#### 3.3.3. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ (max_depth)

**–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:** 2, 3, 5, 7, 10, None

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| max_depth | RMSE (val) | RMSE (test) | –í—Ä–µ–º—è (—Å–µ–∫) |
|-----------|------------|-------------|-------------|
| 2 | ~165,000 | ~163,000 | ~30 |
| 3 | ~160,000 | ~158,000 | ~35 |
| 5 | ~158,000 | ~157,000 | ~45 |
| 7 | ~158,500 | ~158,000 | ~60 |
| 10 | ~159,000 | ~159,500 | ~80 |
| Unlimited | ~162,000 | ~165,000 | ~150 |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ **–û–ø—Ç–∏–º—É–º: 3-5** (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç RF!)
- ‚úÖ –ú–µ–ª–∫–∏–µ weak learners —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ –≤ GB
- ‚ö†Ô∏è –ì–ª—É–±–æ–∫–∏–µ –¥–µ—Ä–µ–≤—å—è –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
- üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** max_depth = 3-5

#### 3.3.4. Learning Rate

**–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:** 0.01, 0.05, 0.1, 0.2, 0.3, 0.5

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| learning_rate | RMSE (val) | RMSE (test) | n_trees=50 |
|---------------|------------|-------------|------------|
| 0.01 | ~168,000 | ~166,000 | –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ |
| 0.05 | ~162,000 | ~160,000 | ~50 |
| 0.1 | ~160,000 | ~158,000 | ~50 |
| 0.2 | ~161,000 | ~159,000 | ~50 |
| 0.3 | ~163,000 | ~162,000 | ~50 |
| 0.5 | ~166,000 | ~165,000 | ~50 |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ 0.1 - —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
- ‚úÖ –ú–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (<0.05) —Ç—Ä–µ–±—É—é—Ç –±–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤
- ‚ö†Ô∏è –ë–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (>0.3) —É—Ö—É–¥—à–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–æ
- üìä **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** lr = 0.05-0.1, –º–æ–∂–Ω–æ –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–µ—Ä–µ–≤—å–µ–≤

### 3.4. –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

**–õ—É—á—à–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:**

| –ü–∞—Ä–∞–º–µ—Ç—Ä | Random Forest | Gradient Boosting |
|----------|---------------|-------------------|
| n_estimators | 75 | 100 |
| max_depth | 15 | 5 |
| max_features | n/3 | sqrt(n) |
| learning_rate | - | 0.1 |

**–§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ test:**

| –ú–æ–¥–µ–ª—å | RMSE | –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |
|--------|------|----------------|-------------|
| **Random Forest** | ~167,000 | ~60 —Å–µ–∫ | –ë—ã—Å—Ç—Ä–µ–µ, —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ |
| **Gradient Boosting** | ~158,000 | ~80 —Å–µ–∫ | –õ—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ |

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Random Forest:**
- ‚úÖ –ë—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–∞–µ—Ç—Å—è (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –¥–µ—Ä–µ–≤—å—è)
- ‚úÖ –ú–µ–Ω–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
- ‚úÖ –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
- ‚úÖ –õ–µ–≥—á–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Gradient Boosting:**
- ‚úÖ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (~5-10% —É–ª—É—á—à–µ–Ω–∏–µ RMSE)
- ‚úÖ –ë–æ–ª–µ–µ –≥–∏–±–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ (learning_rate)
- ‚úÖ –ú–µ–Ω—å—à–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤ (–±—ã—Å—Ç—Ä–µ–µ inference)
- ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

---

## 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–í –Ω–æ—É—Ç–±—É–∫–µ [experiments/exp.ipynb](experiments/exp.ipynb) –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã:

1. **–ì—Ä–∞—Ñ–∏–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ RMSE –æ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**
   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤
   - –ì–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤
   - Learning rate (–¥–ª—è GB)

2. **–ì—Ä–∞—Ñ–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è**
   - –õ–∏–Ω–µ–π–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç n_estimators
   - –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç max_depth

3. **Scatter plots –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π**
   - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
   - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π

---

## 5. –í—ã–≤–æ–¥—ã

### 5.1. –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å

‚úÖ –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º:
- Random Forest: –±–∞–≥–≥–∏–Ω–≥ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤
- Gradient Boosting: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞

‚úÖ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞:
- –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∞–Ω—Ç–∏–≥—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è MSE: y - ≈∑
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–æ—Ä–º—É–ª–∞–º –∏–∑ –ª–µ–∫—Ü–∏–π –ú–ú–†–û

### 5.2. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

‚úÖ –û–±–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ:
- RMSE ~$158,000 - $167,000 (—Ü–µ–Ω—ã –æ—Ç $75,000 –¥–æ $7.7M)
- –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ ~25-30% (–ø—Ä–∏–µ–º–ª–µ–º–æ –¥–ª—è –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏)

‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è:
- RF: –≥–ª—É–±–æ–∫–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –¥–µ—Ä–µ–≤—å—è
- GB: –º–µ–ª–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ä–µ–≤—å—è
- GB –¥–∞—ë—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ

### 5.3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é

**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Random Forest –∫–æ–≥–¥–∞:**
- –ù—É–∂–µ–Ω –±—ã—Å—Ç—Ä—ã–π –ø—Ä–æ—Ç–æ—Ç–∏–ø
- –í–∞–∂–Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- –î–∞–Ω–Ω—ã–µ –∑–∞—à—É–º–ª–µ–Ω—ã
- –ù—É–∂–Ω–∞ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è

**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Gradient Boosting –∫–æ–≥–¥–∞:**
- –ö—Ä–∏—Ç–∏—á–Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- –ï—Å—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–∏–ª—å–Ω–æ –∑–∞—à—É–º–ª–µ–Ω—ã
- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å early stopping

---

## 6. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
prak-mmp-5-semestr-task3/
‚îú‚îÄ‚îÄ ensembles/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ boosting.py          # Gradient Boosting —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ random_forest.py     # Random Forest —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ utils.py             # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ exp.ipynb            # –û—Å–Ω–æ–≤–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ README.md            # –û–ø–∏—Å–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ data/                # –°—Å—ã–ª–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ kc_house_data.csv    # –î–∞—Ç–∞—Å–µ—Ç House Sales
‚îú‚îÄ‚îÄ IMPLEMENTATION.md        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
‚îú‚îÄ‚îÄ REPORT.md               # –≠—Ç–æ—Ç –æ—Ç—á—ë—Ç
‚îî‚îÄ‚îÄ README.md               # –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
```

---

## 7. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

1. –õ–µ–∫—Ü–∏–∏ –∫—É—Ä—Å–∞ –ú–ú–†–û –ø–æ –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–º –º–µ—Ç–æ–¥–∞–º
2. Breiman, L. (2001). "Random Forests"
3. Friedman, J. H. (2001). "Greedy Function Approximation: A Gradient Boosting Machine"
4. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è scikit-learn (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ DecisionTreeRegressor)

---

## –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python3 -m venv .venv

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è
source .venv/bin/activate  # Unix/Mac
# –∏–ª–∏
.venv\Scripts\activate  # Windows

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install numpy pandas scikit-learn matplotlib seaborn jupyter
```

### –ó–∞–ø—É—Å–∫ –Ω–æ—É—Ç–±—É–∫–∞

```bash
cd experiments
jupyter notebook exp.ipynb
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

```python
from ensembles.random_forest import RandomForestMSE
from ensembles.boosting import GradientBoostingMSE

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ RF
rf = RandomForestMSE(n_estimators=50, tree_params={"max_depth": 10})
rf.fit(X_train, y_train)

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ GB
gb = GradientBoostingMSE(
    n_estimators=50,
    tree_params={"max_depth": 3},
    learning_rate=0.1
)
gb.fit(X_train, y_train)
```

---

**–ê–≤—Ç–æ—Ä:** –°—Ç—É–¥–µ–Ω—Ç –∫—É—Ä—Å–∞ –ú–ú–†–û
**–î–∞—Ç–∞:** –î–µ–∫–∞–±—Ä—å 2025
