{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7170a266",
   "metadata": {},
   "source": [
    "# Эксперименты с Random Forest и Gradient Boosting\n",
    "\n",
    "**Датасет**: House Sales in King County, USA\n",
    "\n",
    "**Цель**: Исследовать поведение собственных реализаций Random Forest и Gradient Boosting на реальных данных.\n",
    "\n",
    "## Содержание\n",
    "1. Загрузка и предобработка данных\n",
    "2. Эксперименты с Random Forest\n",
    "3. Эксперименты с Gradient Boosting\n",
    "4. Сравнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f017f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ensembles.random_forest import RandomForestMSE\n",
    "from ensembles.boosting import GradientBoostingMSE\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Загрузка и предобработка данных\n",
    "\n",
    "# Загрузка данных\n",
    "DATA_PATH = Path(\"../data/kc_house_data.csv\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"\\nПервые 5 строк:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83193f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Информация о данных\n",
    "print(\"Информация о столбцах:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nСтатистика:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Предобработка данных\n",
    "\n",
    "# 1. Извлекаем признаки из даты\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"day\"] = df[\"date\"].dt.day\n",
    "\n",
    "# 2. Удаляем ненужные столбцы\n",
    "df = df.drop(columns=[\"date\", \"id\"])\n",
    "\n",
    "# 3. Разделяем на признаки и целевую переменную\n",
    "target = df.pop(\"price\")\n",
    "X = df.copy()\n",
    "\n",
    "# 4. Обрабатываем категориальные признаки (zipcode)\n",
    "# Используем one-hot encoding для zipcode\n",
    "X = pd.get_dummies(X, columns=[\"zipcode\"], prefix=\"zip\")\n",
    "\n",
    "print(f\"Размер признаков после предобработки: {X.shape}\")\n",
    "print(f\"Целевая переменная (price): min={target.min():.0f}, max={target.max():.0f}, mean={target.mean():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68119178",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделение данных на train/validation/test\n",
    "\n",
    "# Сначала отделяем тестовую выборку (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, target, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Затем разделяем оставшиеся данные на train (64%) и validation (16%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Преобразуем в numpy массивы\n",
    "X_train_np = X_train.values.astype(np.float64)\n",
    "X_val_np = X_val.values.astype(np.float64)\n",
    "X_test_np = X_test.values.astype(np.float64)\n",
    "y_train_np = y_train.values.astype(np.float64)\n",
    "y_val_np = y_val.values.astype(np.float64)\n",
    "y_test_np = y_test.values.astype(np.float64)\n",
    "\n",
    "print(\"Размеры выборок:\")\n",
    "print(f\"  Train: {X_train_np.shape[0]} объектов\")\n",
    "print(f\"  Validation: {X_val_np.shape[0]} объектов\")\n",
    "print(f\"  Test: {X_test_np.shape[0]} объектов\")\n",
    "print(f\"  Количество признаков: {X_train_np.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faq3quiz91l",
   "source": "## 2. Эксперименты с Random Forest\n\n### 2.1. Зависимость от количества деревьев",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "wtz903vy1mf",
   "source": "# Исследуем влияние количества деревьев\nn_estimators_list = [5, 10, 20, 30, 50, 75, 100]\n\nresults_rf_n_trees = []\n\nfor n_trees in n_estimators_list:\n    print(f\"Обучение RF с {n_trees} деревьями...\")\n    \n    rf = RandomForestMSE(\n        n_estimators=n_trees,\n        tree_params={\"max_depth\": 10, \"random_state\": 42}\n    )\n    \n    start_time = time.time()\n    rf.fit(X_train_np, y_train_np)\n    train_time = time.time() - start_time\n    \n    # Предсказания\n    y_pred_val = rf.predict(X_val_np)\n    y_pred_test = rf.predict(X_test_np)\n    \n    # RMSE\n    rmse_val = np.sqrt(mean_squared_error(y_val_np, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n    \n    results_rf_n_trees.append({\n        'n_estimators': n_trees,\n        'rmse_val': rmse_val,\n        'rmse_test': rmse_test,\n        'time': train_time\n    })\n    \n    print(f\"  RMSE (val): {rmse_val:,.0f}, RMSE (test): {rmse_test:,.0f}, Time: {train_time:.2f}s\\n\")\n\ndf_rf_n_trees = pd.DataFrame(results_rf_n_trees)\ndf_rf_n_trees",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "winwi2cwucb",
   "source": "# Визуализация зависимости от количества деревьев\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# RMSE\naxes[0].plot(df_rf_n_trees['n_estimators'], df_rf_n_trees['rmse_val'], 'o-', label='Validation', linewidth=2)\naxes[0].plot(df_rf_n_trees['n_estimators'], df_rf_n_trees['rmse_test'], 's-', label='Test', linewidth=2)\naxes[0].set_xlabel('Количество деревьев', fontsize=12)\naxes[0].set_ylabel('RMSE', fontsize=12)\naxes[0].set_title('Random Forest: RMSE vs Количество деревьев', fontsize=14)\naxes[0].legend(fontsize=11)\naxes[0].grid(True, alpha=0.3)\n\n# Время обучения\naxes[1].plot(df_rf_n_trees['n_estimators'], df_rf_n_trees['time'], 'o-', color='green', linewidth=2)\naxes[1].set_xlabel('Количество деревьев', fontsize=12)\naxes[1].set_ylabel('Время обучения (сек)', fontsize=12)\naxes[1].set_title('Random Forest: Время обучения vs Количество деревьев', fontsize=14)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "siatke95vxp",
   "source": "### 2.2. Зависимость от max_features (размерность подвыборки признаков)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "nmh2cppjaqq",
   "source": "# Исследуем влияние max_features\nn_features = X_train_np.shape[1]\nmax_features_list = [int(np.sqrt(n_features)), n_features // 4, n_features // 2, n_features]\n\nresults_rf_max_features = []\n\nfor max_feat in max_features_list:\n    print(f\"Обучение RF с max_features={max_feat}...\")\n    \n    rf = RandomForestMSE(\n        n_estimators=50,\n        tree_params={\"max_depth\": 10, \"max_features\": max_feat, \"random_state\": 42}\n    )\n    \n    start_time = time.time()\n    rf.fit(X_train_np, y_train_np)\n    train_time = time.time() - start_time\n    \n    y_pred_val = rf.predict(X_val_np)\n    y_pred_test = rf.predict(X_test_np)\n    \n    rmse_val = np.sqrt(mean_squared_error(y_val_np, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n    \n    results_rf_max_features.append({\n        'max_features': max_feat,\n        'max_features_ratio': max_feat / n_features,\n        'rmse_val': rmse_val,\n        'rmse_test': rmse_test,\n        'time': train_time\n    })\n    \n    print(f\"  RMSE (val): {rmse_val:,.0f}, RMSE (test): {rmse_test:,.0f}, Time: {train_time:.2f}s\\n\")\n\ndf_rf_max_features = pd.DataFrame(results_rf_max_features)\ndf_rf_max_features",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "qixpddxvzya",
   "source": "### 2.3. Зависимость от максимальной глубины дерева",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dediix5cb15",
   "source": "# Исследуем влияние глубины дерева (включая None - неограниченная глубина)\nmax_depth_list = [3, 5, 10, 15, 20, None]\n\nresults_rf_max_depth = []\n\nfor max_d in max_depth_list:\n    depth_str = str(max_d) if max_d is not None else \"Unlimited\"\n    print(f\"Обучение RF с max_depth={depth_str}...\")\n    \n    rf = RandomForestMSE(\n        n_estimators=30,\n        tree_params={\"max_depth\": max_d, \"random_state\": 42}\n    )\n    \n    start_time = time.time()\n    rf.fit(X_train_np, y_train_np)\n    train_time = time.time() - start_time\n    \n    y_pred_val = rf.predict(X_val_np)\n    y_pred_test = rf.predict(X_test_np)\n    \n    rmse_val = np.sqrt(mean_squared_error(y_val_np, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n    \n    results_rf_max_depth.append({\n        'max_depth': depth_str,\n        'max_depth_num': max_d if max_d is not None else 999,\n        'rmse_val': rmse_val,\n        'rmse_test': rmse_test,\n        'time': train_time\n    })\n    \n    print(f\"  RMSE (val): {rmse_val:,.0f}, RMSE (test): {rmse_test:,.0f}, Time: {train_time:.2f}s\\n\")\n\ndf_rf_max_depth = pd.DataFrame(results_rf_max_depth)\ndf_rf_max_depth",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9flxtjsoo3h",
   "source": "# Визуализация для max_depth\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# RMSE\nx_labels = df_rf_max_depth['max_depth'].values\nx_pos = np.arange(len(x_labels))\naxes[0].bar(x_pos - 0.2, df_rf_max_depth['rmse_val'], 0.4, label='Validation', alpha=0.8)\naxes[0].bar(x_pos + 0.2, df_rf_max_depth['rmse_test'], 0.4, label='Test', alpha=0.8)\naxes[0].set_xticks(x_pos)\naxes[0].set_xticklabels(x_labels, rotation=0)\naxes[0].set_xlabel('Максимальная глубина', fontsize=12)\naxes[0].set_ylabel('RMSE', fontsize=12)\naxes[0].set_title('Random Forest: RMSE vs Максимальная глубина', fontsize=14)\naxes[0].legend(fontsize=11)\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# Время\naxes[1].bar(x_pos, df_rf_max_depth['time'], color='green', alpha=0.8)\naxes[1].set_xticks(x_pos)\naxes[1].set_xticklabels(x_labels, rotation=0)\naxes[1].set_xlabel('Максимальная глубина', fontsize=12)\naxes[1].set_ylabel('Время обучения (сек)', fontsize=12)\naxes[1].set_title('Random Forest: Время обучения vs Максимальная глубина', fontsize=14)\naxes[1].grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8muoqv4fbpr",
   "source": "## 3. Эксперименты с Gradient Boosting\n\n### 3.1. Зависимость от количества деревьев",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "p5ce4zz7ow",
   "source": "# Исследуем влияние количества деревьев для GB\nn_estimators_gb_list = [10, 20, 30, 50, 75, 100, 150]\n\nresults_gb_n_trees = []\n\nfor n_trees in n_estimators_gb_list:\n    print(f\"Обучение GB с {n_trees} деревьями...\")\n    \n    gb = GradientBoostingMSE(\n        n_estimators=n_trees,\n        tree_params={\"max_depth\": 3, \"random_state\": 42},\n        learning_rate=0.1\n    )\n    \n    start_time = time.time()\n    gb.fit(X_train_np, y_train_np)\n    train_time = time.time() - start_time\n    \n    y_pred_val = gb.predict(X_val_np)\n    y_pred_test = gb.predict(X_test_np)\n    \n    rmse_val = np.sqrt(mean_squared_error(y_val_np, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n    \n    results_gb_n_trees.append({\n        'n_estimators': n_trees,\n        'rmse_val': rmse_val,\n        'rmse_test': rmse_test,\n        'time': train_time\n    })\n    \n    print(f\"  RMSE (val): {rmse_val:,.0f}, RMSE (test): {rmse_test:,.0f}, Time: {train_time:.2f}s\\n\")\n\ndf_gb_n_trees = pd.DataFrame(results_gb_n_trees)\ndf_gb_n_trees",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vzj0x7b26qh",
   "source": "# Визуализация GB: количество деревьев\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\naxes[0].plot(df_gb_n_trees['n_estimators'], df_gb_n_trees['rmse_val'], 'o-', label='Validation', linewidth=2)\naxes[0].plot(df_gb_n_trees['n_estimators'], df_gb_n_trees['rmse_test'], 's-', label='Test', linewidth=2)\naxes[0].set_xlabel('Количество деревьев', fontsize=12)\naxes[0].set_ylabel('RMSE', fontsize=12)\naxes[0].set_title('Gradient Boosting: RMSE vs Количество деревьев', fontsize=14)\naxes[0].legend(fontsize=11)\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(df_gb_n_trees['n_estimators'], df_gb_n_trees['time'], 'o-', color='green', linewidth=2)\naxes[1].set_xlabel('Количество деревьев', fontsize=12)\naxes[1].set_ylabel('Время обучения (сек)', fontsize=12)\naxes[1].set_title('Gradient Boosting: Время обучения vs Количество деревьев', fontsize=14)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6ulf61bx",
   "source": "### 3.2. Зависимость от max_features",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "we4ik2wf11",
   "source": "# Влияние max_features для GB\nresults_gb_max_features = []\n\nfor max_feat in max_features_list:\n    print(f\"Обучение GB с max_features={max_feat}...\")\n    \n    gb = GradientBoostingMSE(\n        n_estimators=50,\n        tree_params={\"max_depth\": 3, \"max_features\": max_feat, \"random_state\": 42},\n        learning_rate=0.1\n    )\n    \n    start_time = time.time()\n    gb.fit(X_train_np, y_train_np)\n    train_time = time.time() - start_time\n    \n    y_pred_val = gb.predict(X_val_np)\n    y_pred_test = gb.predict(X_test_np)\n    \n    rmse_val = np.sqrt(mean_squared_error(y_val_np, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n    \n    results_gb_max_features.append({\n        'max_features': max_feat,\n        'max_features_ratio': max_feat / n_features,\n        'rmse_val': rmse_val,\n        'rmse_test': rmse_test,\n        'time': train_time\n    })\n    \n    print(f\"  RMSE (val): {rmse_val:,.0f}, RMSE (test): {rmse_test:,.0f}, Time: {train_time:.2f}s\\n\")\n\ndf_gb_max_features = pd.DataFrame(results_gb_max_features)\ndf_gb_max_features",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "asz2bxk8q1",
   "source": "### 3.3. Зависимость от максимальной глубины",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0d3k9gvoesg",
   "source": "# Влияние глубины для GB (включая неограниченную)\nmax_depth_gb_list = [2, 3, 5, 7, 10, None]\n\nresults_gb_max_depth = []\n\nfor max_d in max_depth_gb_list:\n    depth_str = str(max_d) if max_d is not None else \"Unlimited\"\n    print(f\"Обучение GB с max_depth={depth_str}...\")\n    \n    gb = GradientBoostingMSE(\n        n_estimators=50,\n        tree_params={\"max_depth\": max_d, \"random_state\": 42},\n        learning_rate=0.1\n    )\n    \n    start_time = time.time()\n    gb.fit(X_train_np, y_train_np)\n    train_time = time.time() - start_time\n    \n    y_pred_val = gb.predict(X_val_np)\n    y_pred_test = gb.predict(X_test_np)\n    \n    rmse_val = np.sqrt(mean_squared_error(y_val_np, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n    \n    results_gb_max_depth.append({\n        'max_depth': depth_str,\n        'max_depth_num': max_d if max_d is not None else 999,\n        'rmse_val': rmse_val,\n        'rmse_test': rmse_test,\n        'time': train_time\n    })\n    \n    print(f\"  RMSE (val): {rmse_val:,.0f}, RMSE (test): {rmse_test:,.0f}, Time: {train_time:.2f}s\\n\")\n\ndf_gb_max_depth = pd.DataFrame(results_gb_max_depth)\ndf_gb_max_depth",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "jbisu06jhjo",
   "source": "### 3.4. Зависимость от learning_rate",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ggoajwl7j65",
   "source": "# Влияние learning_rate для GB\nlearning_rate_list = [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n\nresults_gb_lr = []\n\nfor lr in learning_rate_list:\n    print(f\"Обучение GB с learning_rate={lr}...\")\n    \n    gb = GradientBoostingMSE(\n        n_estimators=50,\n        tree_params={\"max_depth\": 3, \"random_state\": 42},\n        learning_rate=lr\n    )\n    \n    start_time = time.time()\n    gb.fit(X_train_np, y_train_np)\n    train_time = time.time() - start_time\n    \n    y_pred_val = gb.predict(X_val_np)\n    y_pred_test = gb.predict(X_test_np)\n    \n    rmse_val = np.sqrt(mean_squared_error(y_val_np, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n    \n    results_gb_lr.append({\n        'learning_rate': lr,\n        'rmse_val': rmse_val,\n        'rmse_test': rmse_test,\n        'time': train_time\n    })\n    \n    print(f\"  RMSE (val): {rmse_val:,.0f}, RMSE (test): {rmse_test:,.0f}, Time: {train_time:.2f}s\\n\")\n\ndf_gb_lr = pd.DataFrame(results_gb_lr)\ndf_gb_lr",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "o35ckq5rm5",
   "source": "# Визуализация для learning_rate\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\naxes[0].plot(df_gb_lr['learning_rate'], df_gb_lr['rmse_val'], 'o-', label='Validation', linewidth=2)\naxes[0].plot(df_gb_lr['learning_rate'], df_gb_lr['rmse_test'], 's-', label='Test', linewidth=2)\naxes[0].set_xlabel('Learning Rate', fontsize=12)\naxes[0].set_ylabel('RMSE', fontsize=12)\naxes[0].set_title('Gradient Boosting: RMSE vs Learning Rate', fontsize=14)\naxes[0].legend(fontsize=11)\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(df_gb_lr['learning_rate'], df_gb_lr['time'], 'o-', color='green', linewidth=2)\naxes[1].set_xlabel('Learning Rate', fontsize=12)\naxes[1].set_ylabel('Время обучения (сек)', fontsize=12)\naxes[1].set_title('Gradient Boosting: Время обучения vs Learning Rate', fontsize=14)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "p27iq9tguuq",
   "source": "## 4. Итоговое сравнение и выводы",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "jfrq5uar9o",
   "source": "# Обучим лучшие модели на основе экспериментов\n\n# Random Forest: лучшая конфигурация\nrf_best = RandomForestMSE(\n    n_estimators=75,\n    tree_params={\"max_depth\": 15, \"random_state\": 42}\n)\n\nstart = time.time()\nrf_best.fit(X_train_np, y_train_np)\nrf_train_time = time.time() - start\n\ny_pred_rf = rf_best.predict(X_test_np)\nrmse_rf = np.sqrt(mean_squared_error(y_test_np, y_pred_rf))\n\n# Gradient Boosting: лучшая конфигурация\ngb_best = GradientBoostingMSE(\n    n_estimators=100,\n    tree_params={\"max_depth\": 5, \"random_state\": 42},\n    learning_rate=0.1\n)\n\nstart = time.time()\ngb_best.fit(X_train_np, y_train_np)\ngb_train_time = time.time() - start\n\ny_pred_gb = gb_best.predict(X_test_np)\nrmse_gb = np.sqrt(mean_squared_error(y_test_np, y_pred_gb))\n\n# Сравнительная таблица\ncomparison = pd.DataFrame({\n    'Модель': ['Random Forest', 'Gradient Boosting'],\n    'RMSE (test)': [rmse_rf, rmse_gb],\n    'Время обучения (сек)': [rf_train_time, gb_train_time]\n})\n\nprint(\"=\"*60)\nprint(\"ИТОГОВОЕ СРАВНЕНИЕ МОДЕЛЕЙ\")\nprint(\"=\"*60)\nprint(comparison.to_string(index=False))\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2k0962z4i0w",
   "source": "# Финальная визуализация: сравнение предсказаний\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Random Forest\naxes[0].scatter(y_test_np, y_pred_rf, alpha=0.5, s=20)\naxes[0].plot([y_test_np.min(), y_test_np.max()], [y_test_np.min(), y_test_np.max()], \n             'r--', lw=2, label='Идеальное предсказание')\naxes[0].set_xlabel('Истинные значения', fontsize=12)\naxes[0].set_ylabel('Предсказанные значения', fontsize=12)\naxes[0].set_title(f'Random Forest\\nRMSE = {rmse_rf:,.0f}', fontsize=14)\naxes[0].legend(fontsize=11)\naxes[0].grid(True, alpha=0.3)\n\n# Gradient Boosting\naxes[1].scatter(y_test_np, y_pred_gb, alpha=0.5, s=20, color='orange')\naxes[1].plot([y_test_np.min(), y_test_np.max()], [y_test_np.min(), y_test_np.max()], \n             'r--', lw=2, label='Идеальное предсказание')\naxes[1].set_xlabel('Истинные значения', fontsize=12)\naxes[1].set_ylabel('Предсказанные значения', fontsize=12)\naxes[1].set_title(f'Gradient Boosting\\nRMSE = {rmse_gb:,.0f}', fontsize=14)\naxes[1].legend(fontsize=11)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ou16de065fo",
   "source": "### Выводы\n\nprint(\"\"\"\nВЫВОДЫ ИЗ ЭКСПЕРИМЕНТОВ:\n\n1. RANDOM FOREST:\n   - Увеличение количества деревьев улучшает качество, но рост замедляется после 50-75 деревьев\n   - Оптимальная глубина деревьев: 10-15 (глубже - переобучение, мельче - недообучение)\n   - Время обучения растёт линейно с количеством деревьев\n   - Неограниченная глубина приводит к переобучению и увеличению времени обучения\n   \n2. GRADIENT BOOSTING:\n   - Более чувствителен к количеству деревьев - качество продолжает улучшаться дольше\n   - Оптимальная глубина базовых деревьев: 3-5 (мелкие деревья работают лучше)\n   - Learning rate 0.1 обеспечивает хороший баланс между качеством и скоростью\n   - Слишком большой learning_rate (>0.3) ухудшает качество\n   - Слишком малый learning_rate (<0.05) требует больше деревьев для сходимости\n   \n3. СРАВНЕНИЕ АЛГОРИТМОВ:\n   - Gradient Boosting обычно показывает лучшее качество при правильной настройке\n   - Random Forest быстрее обучается и менее чувствителен к гиперпараметрам\n   - Random Forest легче параллелится (независимые деревья)\n   - Gradient Boosting требует последовательного обучения деревьев\n   \n4. ПРАКТИЧЕСКИЕ РЕКОМЕНДАЦИИ:\n   - Для быстрого прототипирования: Random Forest с дефолтными параметрами\n   - Для максимального качества: Gradient Boosting с подбором гиперпараметров\n   - Для больших данных: Random Forest (лучше масштабируется)\n   - Для интерпретируемости: Random Forest (более стабильные предсказания)\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbr_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_features\": [\"sqrt\", None],\n",
    "    \"max_depth\": [3, None],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "gbr_results = run_grid(GradientBoostingRegressor, gbr_grid, \"GradientBoosting\")\n",
    "gbr_results.sort_values(\"rmse\").head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}